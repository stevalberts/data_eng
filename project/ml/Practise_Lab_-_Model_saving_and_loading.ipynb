{"cells":[{"cell_type":"markdown","metadata":{},"source":["<p style=\"text-align:center\">\n","    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDB0321ENSkillsNetwork26764238-2022-01-01\" target=\"_blank\">\n","    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n","    </a>\n","</p>\n"]},{"cell_type":"markdown","metadata":{},"source":["### Hands On Lab - Saving and loading a SparkML model\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Objectives:\n","\n","In this lab you will\n","\n","*   Create a simple Linear Regression Model\n","*   Save the SparkML model\n","*   Load the SparkML model\n","*   Make predictions using the loaded SparkML model\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Install pyspark\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip install pyspark\n","!pip install findspark"]},{"cell_type":"markdown","metadata":{},"source":["#### Import libraries\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import findspark\n","findspark.init()"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["from pyspark import SparkContext, SparkConf\n","from pyspark.sql import SparkSession"]},{"cell_type":"markdown","metadata":{},"source":["#### Creating the spark session and context\n"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"ename":"ValueError","evalue":"Cannot run multiple SparkContexts at once; existing SparkContext(app=pyspark-shell, master=local[*]) created by __init__ at /var/folders/ws/c9l_s4sn6bgdlfczk2h4scbr0000gn/T/ipykernel_15644/2045912645.py:6 ","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Creating a spark context class\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m sc \u001b[38;5;241m=\u001b[39m \u001b[43mSparkContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Creating a spark session\u001b[39;00m\n\u001b[1;32m      5\u001b[0m spark \u001b[38;5;241m=\u001b[39m SparkSession \\\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;241m.\u001b[39mbuilder \\\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;241m.\u001b[39mappName(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaving and Loading a SparkML Model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mgetOrCreate()\n","File \u001b[0;32m~/development/ml_eng/.venv/lib/python3.11/site-packages/pyspark/context.py:201\u001b[0m, in \u001b[0;36mSparkContext.__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gateway \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m gateway\u001b[38;5;241m.\u001b[39mgateway_parameters\u001b[38;5;241m.\u001b[39mauth_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    197\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to pass an insecure Py4j gateway to Spark. This\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is not allowed as it is a security risk.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    199\u001b[0m     )\n\u001b[0;32m--> 201\u001b[0m \u001b[43mSparkContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ensure_initialized\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgateway\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgateway\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_init(\n\u001b[1;32m    204\u001b[0m         master,\n\u001b[1;32m    205\u001b[0m         appName,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    215\u001b[0m         memory_profiler_cls,\n\u001b[1;32m    216\u001b[0m     )\n","File \u001b[0;32m~/development/ml_eng/.venv/lib/python3.11/site-packages/pyspark/context.py:449\u001b[0m, in \u001b[0;36mSparkContext._ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    446\u001b[0m     callsite \u001b[38;5;241m=\u001b[39m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context\u001b[38;5;241m.\u001b[39m_callsite\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;66;03m# Raise error if there is already a running Spark context\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    450\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot run multiple SparkContexts at once; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    451\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexisting SparkContext(app=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, master=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    452\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m created by \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m at \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    453\u001b[0m         \u001b[38;5;241m%\u001b[39m (\n\u001b[1;32m    454\u001b[0m             currentAppName,\n\u001b[1;32m    455\u001b[0m             currentMaster,\n\u001b[1;32m    456\u001b[0m             callsite\u001b[38;5;241m.\u001b[39mfunction,\n\u001b[1;32m    457\u001b[0m             callsite\u001b[38;5;241m.\u001b[39mfile,\n\u001b[1;32m    458\u001b[0m             callsite\u001b[38;5;241m.\u001b[39mlinenum,\n\u001b[1;32m    459\u001b[0m         )\n\u001b[1;32m    460\u001b[0m     )\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;241m=\u001b[39m instance\n","\u001b[0;31mValueError\u001b[0m: Cannot run multiple SparkContexts at once; existing SparkContext(app=pyspark-shell, master=local[*]) created by __init__ at /var/folders/ws/c9l_s4sn6bgdlfczk2h4scbr0000gn/T/ipykernel_15644/2045912645.py:6 "]}],"source":["# Creating a spark context class\n","sc = SparkContext()\n","\n","# Creating a spark session\n","spark = SparkSession \\\n","    .builder \\\n","    .appName(\"Saving and Loading a SparkML Model\").getOrCreate()"]},{"cell_type":"markdown","metadata":{},"source":["#### Importing Spark ML libraries\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["from pyspark.ml.feature import VectorAssembler\n","from pyspark.ml.regression import LinearRegression"]},{"cell_type":"markdown","metadata":{},"source":["#### Create a DataFrame with sample data\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["+------+------+\n","|height|weight|\n","+------+------+\n","|    46|   2.5|\n","|    51|   3.4|\n","|    54|   4.4|\n","|    57|   5.1|\n","|    60|   5.6|\n","|    61|   6.1|\n","|    63|   6.4|\n","+------+------+\n","\n"]}],"source":["# Create a simple data set of infant height(cms) weight(kgs) chart.\n","\n","mydata = [[46,2.5],[51,3.4],[54,4.4],[57,5.1],[60,5.6],[61,6.1],[63,6.4]]\n","  \n","# Mention column names of dataframe\n","columns = [\"height\", \"weight\"]\n","  \n","# creating a dataframe\n","mydf = spark.createDataFrame(mydata, columns)\n","  \n","# show data frame\n","mydf.show()"]},{"cell_type":"markdown","metadata":{},"source":["#### Converting data frame columns into feature vectors\n","\n","In this task we use the `VectorAssembler()` function to convert the dataframe columns into feature vectors.\n","For our example, we use the horsepower (\"hp) and weight of the car as input features and the miles-per-gallon (\"mpg\") as target labels.\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["assembler = VectorAssembler(\n","    inputCols=[\"height\"],\n","    outputCol=\"features\")\n","\n","data = assembler.transform(mydf).select('features','weight')"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------+------+\n","|features|weight|\n","+--------+------+\n","|  [46.0]|   2.5|\n","|  [51.0]|   3.4|\n","|  [54.0]|   4.4|\n","|  [57.0]|   5.1|\n","|  [60.0]|   5.6|\n","|  [61.0]|   6.1|\n","|  [63.0]|   6.4|\n","+--------+------+\n","\n"]}],"source":["data.show()"]},{"cell_type":"markdown","metadata":{},"source":["#### Create and Train model\n","\n","We can create the model using the `LinearRegression()` class and train using the `fit()` function.\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["24/10/09 08:38:31 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n","24/10/09 08:38:31 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n","24/10/09 08:38:31 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n"]}],"source":["# Create a LR model\n","lr = LinearRegression(featuresCol='features', labelCol='weight', maxIter=100)\n","lr.setRegParam(0.1)\n","# Fit the model\n","lrModel = lr.fit(data)"]},{"cell_type":"markdown","metadata":{},"source":["#### Save the model\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["lrModel.save('infantheight2.model')"]},{"cell_type":"markdown","metadata":{},"source":["#### Load the model\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# You need LinearRegressionModel to load the model\n","from pyspark.ml.regression import LinearRegressionModel"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["model = LinearRegressionModel.load('infantheight2.model')"]},{"cell_type":"markdown","metadata":{},"source":["#### Make Prediction\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Predict the weight of an infant whose height is 70 CMs.\n"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["# This function converts a scalar number into a dataframe that can be used by the model to predict.\n","def predict(weight):\n","    assembler = VectorAssembler(inputCols=[\"weight\"],outputCol=\"features\")\n","    data = [[weight,0]]\n","    columns = [\"weight\", \"height\"]\n","    _ = spark.createDataFrame(data, columns)\n","    __ = assembler.transform(_).select('features','height')\n","    predictions = model.transform(__)\n","    predictions.select('prediction').show()\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+-----------------+\n","|       prediction|\n","+-----------------+\n","|7.863454719775907|\n","+-----------------+\n","\n"]}],"source":["predict(70)"]},{"cell_type":"markdown","metadata":{},"source":["### Practice exercises\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Save the model as `babyweightprediction.model`\n"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["lrModel.save('babyweightprediction.model')"]},{"cell_type":"markdown","metadata":{},"source":["Double-click **here** for the solution.\n","\n","<!-- Hint:\n","\n","lrModel.save('babyweightprediction.model')\n","-->\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Load the model `babyweightprediction.model`\n"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["model = LinearRegressionModel.load('babyweightprediction.model')"]},{"cell_type":"markdown","metadata":{},"source":["Double-click **here** for the solution.\n","\n","<!-- Hint:\n","\n","model = LinearRegressionModel.load('babyweightprediction.model')\n","-->\n"]},{"cell_type":"markdown","metadata":{},"source":["#### Predict the weight of an infant whose height is 50 CMs.\n"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+------------------+\n","|        prediction|\n","+------------------+\n","|3.4666826711164465|\n","+------------------+\n","\n"]}],"source":["predict(50)"]},{"cell_type":"markdown","metadata":{},"source":["Double-click **here** for the solution.\n","\n","<!-- Hint:\n","\n","predict(50)\n","-->\n"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["# Stop the existing SparkContext if it exists\n","if 'sc' in locals():\n","    sc.stop()\n","\n","# Now create a new SparkContext\n","sc = SparkContext()"]}],"metadata":{"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.10"}},"nbformat":4,"nbformat_minor":4}
